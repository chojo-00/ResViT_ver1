{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3b5934",
   "metadata": {},
   "source": [
    "# Squeeze-and-Excitation (SE) Fusion을 해볼거임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f08c88",
   "metadata": {},
   "source": [
    "핵심 : \"채널별로 중요도를 매겨서 강약 조절을 한다\"\n",
    "\n",
    "\n",
    "작동 원리:\n",
    "두 Feature를 합친(Concat) 후, 신경망이 **\"이 채널(Feature map)은 중요하고, 저 채널은 덜 중요하다\"**는 가중치(Weight)를 계산해 곱해줍니다.\n",
    "공간(Spatial) 정보는 잠시 무시하고, 특징(Feature)의 종류에 집중합니다.\n",
    "\n",
    "장점:\n",
    "가성비 최고: 연산량 증가가 거의 없는데 성능 향상은 확실한 편입니다.\n",
    "구현이 매우 쉽습니다.\n",
    "\n",
    "단점:\n",
    "공간 정보 무시: 영상의 '어느 위치'가 중요한지는 고려하지 않고, 이미지 전체에 대해 채널 중요도만 따집니다.\n",
    "\n",
    "\n",
    "추천 상황: \"기존 학습 속도를 유지하면서, 안정적인 성능 향상을 원할 때\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb05c7",
   "metadata": {},
   "source": [
    "# 변경한 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea937b",
   "metadata": {},
   "source": [
    "##### 1. models/residual_transformers.py에서 아래 코드 추가\n",
    "위치: `ART_block` 클래스 바로 위에 추가\n",
    "\n",
    "```python\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        # Squeeze: [B, C, H, W] → [B, C]\n",
    "        y = self.squeeze(x).view(B, C)\n",
    "        # Excitation: [B, C] → [B, C]\n",
    "        y = self.excitation(y).view(B, C, 1, 1)\n",
    "        # Scale: element-wise multiplication\n",
    "        return x * y.expand_as(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa6224",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0382c2b",
   "metadata": {},
   "source": [
    "##### 2. models/residual_transformers.py에서 아래 코드 추가\n",
    "위치: `self.cc = channel_compression(...)` 바로 아래에 추가\n",
    "\n",
    "```python \n",
    "# 이 코드를 찾아서\n",
    "        self.cc = channel_compression(...) 바로 아래에 추가\n",
    "    # Residual CNN\n",
    "```\n",
    "\n",
    "아래와 같이 수정함.\n",
    "\n",
    "```python\n",
    "        self.cc = channel_compression(ngf * 8, ngf * 4)\n",
    "        # SE Block 추가\n",
    "        self.se = SEBlock(channels=ngf * 8, reduction=16)\n",
    "    # Residual CNN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3a0f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c9a5a",
   "metadata": {},
   "source": [
    "##### 3. ART_block.forward 수정\n",
    "위치:  `torch.cat` 바로 아래\n",
    "```python\n",
    "# 이 코드를 찾아서\n",
    "        # concat transformer output and resnet output\n",
    "        x = torch.cat([transformer_out, x], dim=1)\n",
    "        # channel compression\n",
    "        x = self.cc(x)\n",
    "```\n",
    "\n",
    "아래와 같이 수정함.\n",
    "\n",
    "```python\n",
    "\n",
    "    # concat transformer output and resnet output\n",
    "        x = torch.cat([transformer_out, x], dim=1)\n",
    "        # SE 적용\n",
    "        x = self.se(x)\n",
    "        # channel compression\n",
    "        x = self.cc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5eb5f9",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd010b",
   "metadata": {},
   "source": [
    "# SE 적용 전체 흐름\n",
    "##### 적용 위치\n",
    "**ResViT 전체 구조:**\n",
    "```python\n",
    "encoder_1 → encoder_2 → encoder_3 → [ART_1] → ART_2 → ... → ART_9 → decoder\n",
    "                                       ↑\n",
    "                                    SE 적용 (transformer가 있는 ART block만)\n",
    "```\n",
    "ResViT에서 ART_1과 ART_6만 transformer를 사용함. 따라서 SE는 이 두 블록에서만 작동함.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479776df",
   "metadata": {},
   "source": [
    "### ART_block 내부 흐름 (transformer 있는 경우)\n",
    "\n",
    "```python\n",
    "입력 x [B, 256, 64, 64]  ← encoder_3 출력 (CNN feature)\n",
    "         │\n",
    "         ├──────────────────────────────┐\n",
    "         │                              │\n",
    "         ▼                              │\n",
    "    downsample                          │\n",
    "    [B, 256, 64, 64] → [B, 1024, 16, 16]│\n",
    "         │                              │\n",
    "         ▼                              │\n",
    "    embeddings (patch화)                 │\n",
    "    [B, 1024, 16, 16] → [B, 256, 768]   │\n",
    "         │                              │\n",
    "         ▼                              │\n",
    "    transformer encoder                 │\n",
    "    [B, 256, 768] → [B, 256, 768]       │\n",
    "         │                              │\n",
    "         ▼                              │\n",
    "    reshape                             │\n",
    "    [B, 256, 768] → [B, 768, 16, 16]    │\n",
    "         │                              │\n",
    "         ▼                              │\n",
    "    upsample                            │\n",
    "    [B, 768, 16, 16] → [B, 256, 64, 64] │\n",
    "         │                              │\n",
    "         ▼                              ▼\n",
    "    ┌────────────────────────────────────┐\n",
    "    │  concat                            │\n",
    "    │  Transformer출력 + CNN입력          │\n",
    "    │  [B, 256, 64, 64] + [B, 256, 64, 64]│\n",
    "    │  = [B, 512, 64, 64]                │\n",
    "    └────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "    ┌────────────────────────────────────┐\n",
    "    │  ★ SE Block (새로 추가)            │\n",
    "    │  [B, 512, 64, 64] → [B, 512, 64, 64]│\n",
    "    └────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "    ┌────────────────────────────────────┐\n",
    "    │  channel_compression               │\n",
    "    │  [B, 512, 64, 64] → [B, 256, 64, 64]│\n",
    "    └────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "    ┌────────────────────────────────────┐\n",
    "    │  residual_cnn                      │\n",
    "    │  [B, 256, 64, 64] → [B, 256, 64, 64]│\n",
    "    └────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "              출력 [B, 256, 64, 64]\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debdae8",
   "metadata": {},
   "source": [
    "### SE Block 내부 동작\n",
    "\n",
    "```python\n",
    "입력: concat된 feature [B, 512, 64, 64]\n",
    "      ├─ 채널 0~255: Transformer 출력\n",
    "      └─ 채널 256~511: CNN 입력\n",
    "\n",
    "Step 1: Squeeze (Global Average Pooling)\n",
    "        [B, 512, 64, 64] → [B, 512, 1, 1] → [B, 512]\n",
    "        각 채널을 하나의 숫자로 요약\n",
    "\n",
    "Step 2: Excitation (FC layers)\n",
    "        [B, 512] → FC → [B, 32] → ReLU → FC → [B, 512] → Sigmoid\n",
    "        채널별 중요도 점수 (0~1) 계산\n",
    "        \n",
    "        예: [0.9, 0.8, 0.2, 0.7, ...]\n",
    "            채널0 중요, 채널2 덜 중요\n",
    "\n",
    "Step 3: Scale (곱하기)\n",
    "        [B, 512, 64, 64] × [B, 512, 1, 1]\n",
    "        각 채널에 해당 점수를 곱함\n",
    "\n",
    "출력: 재조정된 feature [B, 512, 64, 64]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 실제 효과 예시\n",
    "\n",
    "```python\n",
    "이미지 A (뼈가 두드러진 CT):\n",
    "- Transformer 채널들: 평균 점수 0.85 (강조됨)\n",
    "- CNN 채널들: 평균 점수 0.60\n",
    "\n",
    "이미지 B (연조직 위주 CT):\n",
    "- Transformer 채널들: 평균 점수 0.55\n",
    "- CNN 채널들: 평균 점수 0.80 (강조됨)\n",
    "\n",
    "→ 이미지마다 Transformer/CNN 비중이 자동 조절됨\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
